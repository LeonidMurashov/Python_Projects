{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY\n",
    "top_k_categorical_accuracy\n",
    "https://stackoverflow.com/questions/47887533/keras-convolution-along-samples\n",
    "https://keras.io/layers/wrappers/#timedistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file differs from 'training_simple_single' by new data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "input_width = 160\n",
    "input_height = 100\n",
    "channels = 3\n",
    "class_number = 12\n",
    "data_path = \"D:\\\\Python\\\\Keras\\\\Wormax\\\\data_prepared\\\\\"\n",
    "model_name = 'models/worm_single_xceptiondelme.h5'\n",
    "look_forward = 1\n",
    "use_rotation = False\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers, models, optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "def actual_acc(y_true, y_pred):\n",
    "    return K.equal(K.argmax(y_pred), K.argmax(y_true))\n",
    "\n",
    "def define_model():\n",
    "    '''model = models.Sequential()\n",
    "        \n",
    "    model.add(layers.Convolution2D(64, (8, 8), strides=(4, 4), activation='relu',\n",
    "                            input_shape=(input_height, input_width, channels)))\n",
    "    model.add(layers.Convolution2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(class_number, activation='softmax'))    '''\n",
    "    model = keras.applications.mobilenetv2.MobileNetV2(include_top=True, \n",
    "                                                       weights=None, \n",
    "                                                       input_tensor=None, \n",
    "                                                       input_shape=(input_height, input_width, channels), \n",
    "                                                       pooling=None, \n",
    "                                                       classes=12)\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[actual_acc])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 50, 80, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 50, 80, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 50, 80, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 50, 80, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 50, 80, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 50, 80, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 50, 80, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 50, 80, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 50, 80, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 50, 80, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 50, 80, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 25, 40, 96)   864         block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 25, 40, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 25, 40, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 25, 40, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 25, 40, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 25, 40, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 25, 40, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 25, 40, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 25, 40, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 25, 40, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 25, 40, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 25, 40, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 25, 40, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 25, 40, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 25, 40, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 25, 40, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 25, 40, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 13, 20, 144)  1296        block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 13, 20, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 13, 20, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 13, 20, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 13, 20, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 13, 20, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 13, 20, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 13, 20, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 13, 20, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 13, 20, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 13, 20, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 13, 20, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 13, 20, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 13, 20, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 13, 20, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 13, 20, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 13, 20, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 13, 20, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 13, 20, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 13, 20, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 13, 20, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 13, 20, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 13, 20, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 13, 20, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 13, 20, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 13, 20, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 7, 10, 192)   1728        block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 7, 10, 192)   768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 7, 10, 192)   0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 7, 10, 64)    12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 7, 10, 64)    256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 7, 10, 384)   24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 7, 10, 384)   1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 7, 10, 384)   0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 7, 10, 384)   3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 7, 10, 384)   1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 7, 10, 384)   0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 7, 10, 64)    24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 7, 10, 64)    256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 7, 10, 64)    0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 7, 10, 384)   24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 7, 10, 384)   1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 7, 10, 384)   0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 7, 10, 384)   3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 7, 10, 384)   1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 7, 10, 384)   0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 7, 10, 64)    24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 7, 10, 64)    256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 7, 10, 64)    0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 7, 10, 384)   24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 7, 10, 384)   1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 7, 10, 384)   0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 7, 10, 384)   3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 7, 10, 384)   1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 7, 10, 384)   0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 7, 10, 64)    24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 7, 10, 64)    256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 7, 10, 64)    0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 7, 10, 384)   24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 7, 10, 384)   1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 7, 10, 384)   0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 7, 10, 384)   3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 7, 10, 384)   1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 7, 10, 384)   0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 7, 10, 96)    36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 7, 10, 96)    384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 7, 10, 576)   55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 7, 10, 576)   2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 7, 10, 576)   0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 7, 10, 576)   5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 7, 10, 576)   2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 7, 10, 576)   0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 7, 10, 96)    55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 7, 10, 96)    384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 7, 10, 96)    0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 7, 10, 576)   55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 7, 10, 576)   2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 7, 10, 576)   0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 7, 10, 576)   5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 7, 10, 576)   2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 7, 10, 576)   0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 7, 10, 96)    55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 7, 10, 96)    384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 7, 10, 96)    0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 7, 10, 576)   55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 7, 10, 576)   2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 7, 10, 576)   0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 4, 5, 576)    5184        block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 4, 5, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 4, 5, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 4, 5, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 4, 5, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 4, 5, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 4, 5, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 4, 5, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 4, 5, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 4, 5, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 4, 5, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 4, 5, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 4, 5, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 4, 5, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 4, 5, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 4, 5, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 4, 5, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 4, 5, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 4, 5, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 4, 5, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 4, 5, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 4, 5, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 4, 5, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 4, 5, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 4, 5, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 4, 5, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 4, 5, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 4, 5, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 4, 5, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 4, 5, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 4, 5, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 4, 5, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 4, 5, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 4, 5, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Logits (Dense)                  (None, 12)           15372       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 2,239,244\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little prepocessing\n",
    "from math import atan2, pi\n",
    "import cv2\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return atan2(y, x)\n",
    "\n",
    "def get_direction(x, y, n_classes = 12):\n",
    "    return round(get_angle(x, y)/2/pi*n_classes)%n_classes\n",
    "\n",
    "# Rotating frame and direction counter-clockwise\n",
    "def get_rotated_frame(img, rotation, target_direction, n_classes):\n",
    "    if rotation != 0:\n",
    "        rows, cols = len(img),len(img[0])\n",
    "        rot_M = cv2.getRotationMatrix2D((cols/2, rows/2), rotation*360/n_classes, 1)\n",
    "        img = cv2.warpAffine(img, rot_M, (cols, rows))\n",
    "        target = (target_direction - rotation)%n_classes\n",
    "    return img, target_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Training and validation\n",
    "data_ratio = 0.7\n",
    "\n",
    "def generator(data_dir, n_classes, role, shuffle=True, batch_size=128):\n",
    "    \n",
    "    listdir = []\n",
    "    listdir = filter(lambda x: os.path.isfile, os.listdir(data_dir))\n",
    "    listdir = np.array(list(listdir))\n",
    "    random.shuffle(listdir)\n",
    "    \n",
    "    #print('Found {} files for {}'.format(len(listdir), role))\n",
    "    \n",
    "    file_i = 0\n",
    "    while 1:\n",
    "        arr = np.load(data_dir + listdir[file_i])        \n",
    "        file_i = (file_i+1) if file_i+1<len(listdir) else 0\n",
    "        \n",
    "        # Expanding blocks\n",
    "        data = []        \n",
    "        for i in arr:\n",
    "            for j in i:\n",
    "                data.append(j)\n",
    "        data = np.array(data)\n",
    "\n",
    "        \n",
    "        if role == 'train':\n",
    "            data = data[:int(round(len(data)*data_ratio))]\n",
    "        elif role == 'validation':\n",
    "            data = data[int(round(len(data)*data_ratio)):]\n",
    "        else:\n",
    "            raise 'bad role parameter'\n",
    "        \n",
    "        # Generating y\n",
    "        data_targets = np.zeros((len(data)-look_forward))\n",
    "        for i in range(len(data_targets)):\n",
    "            data_targets[i] = get_direction(*data[i+look_forward][1][:2])\n",
    "            #data_targets[i] = np.array(to_categorical(get_direction(*data[i+look_forward][1][:2]), num_classes=num_classes))\n",
    "        data = data[:len(data)-look_forward]\n",
    "        \n",
    "        # Only X\n",
    "        data_features = np.zeros((len(data), input_height, input_width, channels))\n",
    "        for i in range(len(data)):\n",
    "            data_features[i] = data[i][0][0]\n",
    "        \n",
    "        indexes = np.arange(len(data_features)-look_forward)        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "        \n",
    "        # Rotating cycle(no rotation for validation)\n",
    "        rotate_times = n_classes if role == 'train' and use_rotation else 1\n",
    "        for rot_i in range(rotate_times):\n",
    "            # Batches forming cycle\n",
    "            for i in range(0, len(data)-look_forward-batch_size, batch_size):\n",
    "                samples = data_features.take(indexes[i:i+batch_size], axis=0)\n",
    "                targets = data_targets.take(indexes[i:i+batch_size], axis=0)\n",
    "                samples_rot = np.zeros_like(samples)\n",
    "                targets_rot = np.zeros((batch_size, n_classes))\n",
    "                \n",
    "                # Rotating\n",
    "                for j in range(batch_size):\n",
    "                    if use_rotation:\n",
    "                        rotation = (rot_i+j+i)%n_classes\n",
    "                        img, target = get_rotated_frame(samples[j], rotation, targets[j], n_classes)\n",
    "                    else:\n",
    "                        img, target = samples[j], targets[j]\n",
    "                    samples_rot[j] = img\n",
    "                    targets_rot[j] = to_categorical(target, num_classes=n_classes)\n",
    "                    \n",
    "                # Normilize\n",
    "                samples_rot = samples_rot / 255\n",
    "                yield samples_rot, targets_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 100, 160, 3)\n",
      "(16, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_generator = generator(data_path, class_number, 'train', batch_size=16)\n",
    "validation_generator = generator(data_path, class_number, 'validation', batch_size=32)\n",
    "\n",
    "print(next(train_generator)[0].shape)\n",
    "print(next(train_generator)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count class instances count for balancing\n",
    "if False:\n",
    "    i = 0\n",
    "    classes = np.zeros((class_number))\n",
    "    for samples, targets in generator(data_path, class_number, 'train', batch_size=1024):\n",
    "        for j in targets:\n",
    "            classes += j\n",
    "        i += 1\n",
    "        if i == 100:\n",
    "            break\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### tensorboard --logdir=D:\\Python\\Keras\\Wormax\\log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "    2) tune look_forward\n",
    "    3) change target to angle\n",
    "    4) fight overfitting on adam\n",
    "    5) Take away poolingb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am trying to solve classification task. Basically, teaching game bot on human actions.  \n",
    "So there are more than 1 right answers for X. But my dataset contains specific actions.\n",
    "\n",
    "Assume the desirable answer is:`[0, 0.7, 0, 0.7, 0.1]`  \n",
    "But dataset contains one-hots like: `[0, 0, 0, 1, 0]`\n",
    "\n",
    "So my idea is to implement Q-state neural network with 2 inputs.  \n",
    "Q(S,a) - where, S - current state, a - action, result is one number(desire to choose this action).  \n",
    "And then I can feed to it my X->y dataset.\n",
    "\n",
    "I am struggling with initializing model. Default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "if not True:\n",
    "    model.load_weights(model_name)\n",
    "    initial_epoch = 176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 3.2082 - actual_acc: 0.0981 - val_loss: 7.3228 - val_actual_acc: 0.0661\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 3.0732 - actual_acc: 0.1175 - val_loss: 6.6997 - val_actual_acc: 0.0683\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 2.9578 - actual_acc: 0.1556 - val_loss: 7.8099 - val_actual_acc: 0.0894\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.8573 - actual_acc: 0.1781 - val_loss: 7.1448 - val_actual_acc: 0.0850\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 2.6135 - actual_acc: 0.2575 - val_loss: 9.3119 - val_actual_acc: 0.0734\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 2.3327 - actual_acc: 0.3450 - val_loss: 9.4745 - val_actual_acc: 0.0908\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 2.1687 - actual_acc: 0.3875 - val_loss: 11.2421 - val_actual_acc: 0.0509\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.1985 - actual_acc: 0.3937 - val_loss: 10.1145 - val_actual_acc: 0.0647\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 2.5479 - actual_acc: 0.2656 - val_loss: 11.0843 - val_actual_acc: 0.0560\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 2.2873 - actual_acc: 0.3250 - val_loss: 10.1400 - val_actual_acc: 0.0574\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 2.1353 - actual_acc: 0.3881 - val_loss: 5.3039 - val_actual_acc: 0.1301\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.1746 - actual_acc: 0.3606 - val_loss: 6.3552 - val_actual_acc: 0.1301\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 2.2035 - actual_acc: 0.3575 - val_loss: 6.6332 - val_actual_acc: 0.1141\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 1.9707 - actual_acc: 0.4269 - val_loss: 4.6326 - val_actual_acc: 0.1032\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 1.8579 - actual_acc: 0.4419 - val_loss: 8.6487 - val_actual_acc: 0.0872\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 2.1513 - actual_acc: 0.3606 - val_loss: 9.6219 - val_actual_acc: 0.0632\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.0859 - actual_acc: 0.3937 - val_loss: 6.8031 - val_actual_acc: 0.1185\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 1.8882 - actual_acc: 0.4312 - val_loss: 7.5430 - val_actual_acc: 0.1337\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 1.7443 - actual_acc: 0.4681 - val_loss: 9.0572 - val_actual_acc: 0.0872\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 43s 430ms/step - loss: 2.2750 - actual_acc: 0.3306 - val_loss: 8.4439 - val_actual_acc: 0.1265\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 1.9507 - actual_acc: 0.4319 - val_loss: 7.6107 - val_actual_acc: 0.1097\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 1.8249 - actual_acc: 0.4469 - val_loss: 6.6819 - val_actual_acc: 0.1344\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.9248 - actual_acc: 0.4394 - val_loss: 6.8801 - val_actual_acc: 0.0770\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.1424 - actual_acc: 0.3825 - val_loss: 12.0279 - val_actual_acc: 0.0669\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.7601 - actual_acc: 0.4862 - val_loss: 8.9005 - val_actual_acc: 0.0836\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 1.6381 - actual_acc: 0.5062 - val_loss: 10.3861 - val_actual_acc: 0.1112\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 58s 584ms/step - loss: 1.5237 - actual_acc: 0.5613 - val_loss: 10.6693 - val_actual_acc: 0.1061\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4213 - actual_acc: 0.2969 - val_loss: 11.6259 - val_actual_acc: 0.0698\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.8774 - actual_acc: 0.4387 - val_loss: 9.8101 - val_actual_acc: 0.0596\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 1.7553 - actual_acc: 0.4806 - val_loss: 6.7143 - val_actual_acc: 0.1090\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.7980 - actual_acc: 0.4813 - val_loss: 11.1692 - val_actual_acc: 0.0814\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 2.1903 - actual_acc: 0.3581 - val_loss: 10.4299 - val_actual_acc: 0.1017\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.8773 - actual_acc: 0.4394 - val_loss: 11.0258 - val_actual_acc: 0.0770\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 1.7481 - actual_acc: 0.4738 - val_loss: 10.2301 - val_actual_acc: 0.0901\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.6872 - actual_acc: 0.4956 - val_loss: 12.6147 - val_actual_acc: 0.0647\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 2.1219 - actual_acc: 0.3844 - val_loss: 7.8412 - val_actual_acc: 0.1083\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 1.5568 - actual_acc: 0.5306 - val_loss: 10.8988 - val_actual_acc: 0.0640\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.6689 - actual_acc: 0.5269 - val_loss: 10.6122 - val_actual_acc: 0.0938\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.1246 - actual_acc: 0.3769 - val_loss: 6.6188 - val_actual_acc: 0.1054\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 1.7240 - actual_acc: 0.4988 - val_loss: 6.9034 - val_actual_acc: 0.1352\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5494 - actual_acc: 0.5525 - val_loss: 10.8905 - val_actual_acc: 0.0785\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 1.6935 - actual_acc: 0.5212 - val_loss: 7.6380 - val_actual_acc: 0.1177\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 2.0883 - actual_acc: 0.3850 - val_loss: 7.3115 - val_actual_acc: 0.1177\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 1.7001 - actual_acc: 0.4937 - val_loss: 6.9988 - val_actual_acc: 0.1613\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5061 - actual_acc: 0.5494 - val_loss: 5.7702 - val_actual_acc: 0.1592\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.9217 - actual_acc: 0.4637 - val_loss: 7.1232 - val_actual_acc: 0.1039\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.8642 - actual_acc: 0.4738 - val_loss: 4.9380 - val_actual_acc: 0.1410\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.5119 - actual_acc: 0.5575 - val_loss: 5.8524 - val_actual_acc: 0.1424\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 1.4184 - actual_acc: 0.5844 - val_loss: 5.1132 - val_actual_acc: 0.1330\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.7894 - actual_acc: 0.4825 - val_loss: 6.0087 - val_actual_acc: 0.1395\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 2.0190 - actual_acc: 0.3994 - val_loss: 5.5102 - val_actual_acc: 0.1148\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.7142 - actual_acc: 0.4838 - val_loss: 4.9025 - val_actual_acc: 0.1490\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 1.5012 - actual_acc: 0.5569 - val_loss: 4.7609 - val_actual_acc: 0.1548\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 1.7503 - actual_acc: 0.4794 - val_loss: 7.3989 - val_actual_acc: 0.1090\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 179ms/step - loss: 1.9482 - actual_acc: 0.4325 - val_loss: 6.6079 - val_actual_acc: 0.1272\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 1.6844 - actual_acc: 0.4931 - val_loss: 5.5222 - val_actual_acc: 0.1410\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 1.5324 - actual_acc: 0.5337 - val_loss: 4.7149 - val_actual_acc: 0.1446\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.6627 - actual_acc: 0.5044 - val_loss: 8.2303 - val_actual_acc: 0.1119\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 1.9918 - actual_acc: 0.3981 - val_loss: 4.9929 - val_actual_acc: 0.1541\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 1.6403 - actual_acc: 0.5031 - val_loss: 4.6097 - val_actual_acc: 0.1315\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 1.5746 - actual_acc: 0.5369 - val_loss: 3.9224 - val_actual_acc: 0.1657\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.9536 - actual_acc: 0.4169 - val_loss: 5.0648 - val_actual_acc: 0.1068\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 2.0086 - actual_acc: 0.4006 - val_loss: 2.8782 - val_actual_acc: 0.2144\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 1.6738 - actual_acc: 0.5037 - val_loss: 3.5842 - val_actual_acc: 0.1904\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 1.5676 - actual_acc: 0.5212 - val_loss: 4.2518 - val_actual_acc: 0.1483\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.8994 - actual_acc: 0.4494 - val_loss: 5.3063 - val_actual_acc: 0.1548\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 1.8374 - actual_acc: 0.4625 - val_loss: 4.3847 - val_actual_acc: 0.2151\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 1.5214 - actual_acc: 0.5588 - val_loss: 5.1826 - val_actual_acc: 0.1577\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 1.7198 - actual_acc: 0.5125 - val_loss: 5.7524 - val_actual_acc: 0.0872\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.9582 - actual_acc: 0.4069 - val_loss: 4.4002 - val_actual_acc: 0.1533\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 1.6376 - actual_acc: 0.5062 - val_loss: 3.9205 - val_actual_acc: 0.2260\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.4350 - actual_acc: 0.5469 - val_loss: 5.2437 - val_actual_acc: 0.1519\n",
      "Epoch 73/500\n",
      "  4/100 [>.............................] - ETA: 14s - loss: 1.4749 - actual_acc: 0.5938"
     ]
    }
   ],
   "source": [
    "if not use_rotation:\n",
    "    class_weight = {0: 1.15,\n",
    "                     1: 1.13,\n",
    "                     2: 1.27,\n",
    "                     3: 1.51,\n",
    "                     4: 1.46,\n",
    "                     5: 1.19,\n",
    "                     6: 1.0,\n",
    "                     7: 1.04,\n",
    "                     8: 1.11,\n",
    "                     9: 1.2,\n",
    "                     10: 1.27,\n",
    "                     11: 1.34}\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log_dir\\\\' + model_name\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "    \n",
    "]\n",
    "'''keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.5,                              \n",
    "        patience=70, \n",
    "        min_lr=0.00001\n",
    "    )'''\n",
    "\n",
    "steps_per_epoch = 100\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=500,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=int(round(steps_per_epoch/data_ratio*(1-data_ratio))),\n",
    "                            shuffle=True,\n",
    "                            class_weight=class_weight,\n",
    "                            callbacks=callbacks,\n",
    "                            initial_epoch=initial_epoch\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "    1)   \n",
    "    2) baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
